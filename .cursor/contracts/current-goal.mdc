---
description: Active goal manifest — single-read orientation for agents to know what matters now
---

# Current Goal

**Goal:** System Refinement  
**Summary:** The PoC proved Asterisk works (M19=0.83 heuristic, 0.58 AI). The demo exposed the gaps: arbitrary thresholds, no principled "good enough" analysis, calibration locked in Asterisk-specific code instead of being an Origami framework concern. Now refine: principled scorecard, calibration as a first-class pipeline, and a system whose metrics are grounded in business ROI — not engineering intuition.

## The ROI That Changes Everything

$1 per 20 cases saves 10 people an accumulated 10 days of work.

| Factor | Value |
|--------|-------|
| AI cost per batch | ~$1 |
| Labor savings per batch | ~$50,000 |
| ROI | **50,000x** |

**Implication:** Accuracy dominates. Token budget is irrelevant. A system that costs $5 instead of $1 but gets the answer right saves $49,995.

## Vision

**Asterisk (the product):** A system whose accuracy is measured against principled, ROI-grounded thresholds. When a metric passes, it means "this is good enough to save human time." When it fails, it means "this specific gap costs humans $X."

**Origami (the engine):** A framework where calibration is a first-class citizen. Declarative `ScoreCard` YAML defines metrics. The calibration runner is itself a DSL pipeline — visible in Kami, debuggable, shareable. Origami eats its own dog food.

## PoC Results (baseline)

| Adapter | Scenario | M19 | Key metrics | Notes |
|---------|----------|-----|-------------|-------|
| BasicAdapter | ptp-real-ingest (18 verified) | **0.83** | M1=1.00, M2=1.00, M15=0.72 | Heuristic baseline. 19/21 metrics pass. |
| CursorAdapter | ptp-real-ingest (18 verified) | **0.58** | M2=0.78, M8=0.60, M14b=0.30 | AI baseline. 10/21 pass. Root causes documented. |

Full PoC history: `notes/goal-history-poc.md`

## Execution Order

**Principle: break early, stabilize later.** Contracts that introduce breaking API changes go in R1-R2 so consumers absorb all breakage in one window. Additive features fill R3-R4. No "floating" contracts — everything has a sprint.

### Sprint R1 — Foundation: Scorecard + Breaking Framework Changes

The big bang. Scorecard gates everything, but we also land all breaking Origami API changes here so Asterisk only has one painful `go get` upgrade. E2E tests gate the checkpoint. CLI scaffold starts in parallel.

| # | Contract | Repo | Tier | Breaking? | Notes |
|---|----------|------|------|-----------|-------|
| R1a | `principled-calibration-scorecard` Ph1-5 | **Both** | gate | yes | `MetricDef`, `ScoreCard`, `CostTier`, `EvalDirection` types. MetricSet flattened. `DefaultMetrics()` (7 universal). TokiMeter migrated to Origami `CostBill`. Declarative YAML. M19 reweight. |
| R1b | `consumer-cli-scaffold` | Origami | should | yes | 8 perennial commands, `origami.NewCLI()` builder. Replaces ~780 lines Cobra per consumer. |
| R1c | `e2e-dsl-testing` | Origami | should | no | E2E walk tests gate this and every subsequent checkpoint. |
| R1d | `durable-execution` | Origami | should | yes | `Checkpointer` interface + HITL Interrupt/Resume. Changes walk contract. |
| R1e | `evidence-gap-brief` | **Asterisk** | nice | no | Structured "I don't know" output. Improves M8 (convergence calibration). |
| R1f | `origami-adapters` | Origami | should | yes | FQCN resolution rewrites all registry `.Get()` methods. `imports:` on PipelineDef. Core adapter. |
| R1g | `memory-evolution` | Origami | should | yes | `MemoryStore` interface changes: namespaced, searchable, persistent. Break once, not twice. |
| R1h | `origami-observability` | Origami | should | yes | Day-0 OTel traces + Prometheus metrics. `/metrics` on KamiServer. `DefaultObservability()`. TokenTracker Prometheus-counter-friendly. |
| R1i | `origami-api-hygiene` | Origami | should | yes | Configurable `ModelRegistry`, rename `curate.Source` → `curate.EvidenceSource`, parameterize probe stimuli. Consumer impact: rename `curate.Source` references. |

**Deliverables:**
- `MetricDef`, `ScoreCard`, `CostTier`, `EvalDirection` types in Origami
- `MetricSet` flattened — `Metrics []Metric` replaces 6-group struct, `ByTier()`/`ByID()` view methods
- `DefaultMetrics()` — 7 universal metrics ship with framework (token_usage, token_cost_usd, latency_seconds, path_efficiency, loop_ratio, confidence_calibration, run_variance)
- `DefaultScoreCard()` — three-layer API (primitives → defaults → consumer extension)
- `asterisk-rca-scorecard.yaml` replaces hardcoded thresholds, M19 reweighted, M14b promoted, M18 raised to 200K
- TokiMeter cost bill migrated to `origami/dispatch/cost_bill.go` — every dispatch gets a cost bill, not just calibration. `tokimeter.go` deleted from Asterisk
- `FormatTokenSummary` bug fix — uses `CostConfig`, not hardcoded 3.0/15.0
- `origami.NewCLI()` builder API with 8 commands
- `Checkpointer` interface + `Interrupt/Resume` primitive
- FQCN resolution on all registries, `imports:` field on `PipelineDef`, core adapter
- `MemoryStore` interface with namespaces, search, persistence
- `EvidenceGap` type and gap brief output
- OTel traces for every pipeline walk + Prometheus `/metrics` endpoint on KamiServer
- E2E test suite gates checkpoint

### CHECKPOINT R1 — Foundation validated

```
Origami:  go build ./... && go test ./...
          go test ./... -run TestE2E (all E2E scenarios)
Asterisk: go get github.com/dpopsuev/origami@latest
          go build ./... && go test ./...
          just calibrate-stub (with new thresholds)
```

Verify: New thresholds applied. Stub calibration passes. BasicAdapter M19 >= 0.70. FQCN resolution works. CLI scaffold builds. Checkpointer interface compiles. MemoryStore interface compiles. E2E tests green.

### Sprint R2 — Pipelines + Structural Node Changes

All DSL pipeline work lands here. Also structural additions to the node system (marbles, caching) that are additive but change how graphs are built and walked.

| # | Contract | Repo | Tier | Breaking? | Notes |
|---|----------|------|------|-----------|-------|
| R2a | `principled-calibration-scorecard` Ph6 | **Both** | should | no | Express calibration runner as DSL pipeline. Visible in Kami. Dog-foods Origami. |
| R2b | `refine-rtfm-routing-policy` | **Both** | should | yes* | `ReadPolicy` replaces RTFM entirely. Delete `context` node, `internal/rtfm/`. (*breaking to Asterisk pipeline, not Origami API) |
| R2c | `data-ingestion-pipeline` | **Asterisk** | should | no | Data ingestion as DSL pipeline. `consume run` via CRON. `dataset review/promote`. |
| R2d | `origami-marbles` | Origami | should | yes | `Marble` interface, `marble:` field on `NodeDef`, `MarbleRegistry`, composite subgraph. |
| R2e | `pipeline-efficiency` | Origami | should | yes | Node caching in walk loop. `parallel:` fan-in merge strategies. |
| R2f | `provider-resilience` | Origami | nice | no | Dispatch fallback chains + intent classifier. Additive to existing dispatch. |

### CHECKPOINT R2 — Pipelines validated

```
Origami:  go build ./... && go test ./...
          go test ./... -run TestE2E
Asterisk: go get github.com/dpopsuev/origami@latest
          go build ./... && go test ./...
          just calibrate-stub (via DSL pipeline)
          asterisk consume run --dry-run
```

Verify: DSL calibration identical to procedural. RTFM deleted — context node gone, always-read content in prompts. Ingestion pipeline validates. Marble system compiles. Node caching works. Fallback chains configured.

### Sprint R3 — CursorAdapter Tuning + Knowledge Deepening

Tuning sprint. The framework is stable. Now use the principled scorecard to guide AI improvement, add prompt feedback loops, and deepen the knowledge layer.

| # | Contract | Repo | Tier | Breaking? | Notes |
|---|----------|------|------|-----------|-------|
| R3a | (new contract TBD) | **Asterisk** | should | no | Systematic CursorAdapter improvement. Focus on M1, M10, M15 (highest ROI metrics). |
| R3b | `prompt-calibration` | Origami | nice | no | Feedback loop: calibration results → prompt improvements. Uses ScoreCard from R1. |
| R3c | `knowledge-source-evolution` | **Asterisk** | nice | no | Layered composition via `Source.Tags`, artifact dependency graph. Post-ReadPolicy. |

### CHECKPOINT R3 — CursorAdapter improvement

```
Asterisk: just calibrate-wet --cases 18
```

Target: CursorAdapter M19 >= 0.70 (up from 0.58). At minimum 15/21 metrics pass (up from 10/21).

### Sprint R4 — Re-Demo + LSP

The framework is stable, the AI works, now polish and present. LSP needs the stable DSL from all prior sprints.

| # | Contract | Repo | Tier | Breaking? | Notes |
|---|----------|------|------|-----------|-------|
| R4a | `improve-asterisk-kabuki-demo` | **Both** | should | no | Three-act narrative with principled results. War Room shows calibration pipeline in Kami. |
| R4b | `origami-lsp` | Origami | vision | no | Language Server for pipeline YAML. Needs stable DSL from R1-R3. Color coding, completion, Kami live connection. |

### CHECKPOINT R4 — Demo + LSP validated

```
Origami:  go build ./... && go test ./...
Asterisk: go build ./... && go test ./...
          asterisk demo --replay
```

Verify: Demo runs end-to-end with all sections. War Room populated. Results show principled metrics. LSP validates all E2E scenario YAMLs without false diagnostics.

**Closed/absorbed:**
- ~~`domain-calibration`~~ → absorbed into `principled-calibration-scorecard` Phase 6
- ~~`ground-truth-dataset`~~ → absorbed by `data-ingestion-pipeline` + `consumer-cli-scaffold`
- ~~`knowledge-source-migration`~~ → Phase 1 done, remainder absorbed by `refine-rtfm-routing-policy` + `knowledge-source-evolution`

## Previous Goal History

### Polishing & Presentation (paused)

Sprints 1-5 completed. CHECKPOINT E passed. Demo built but mock PoC exposed foundational gaps:
- Thresholds are arbitrary — no principled "good enough" analysis
- Calibration is Asterisk-locked — not a reusable framework concern
- CursorAdapter at M19=0.58 — the AI doesn't reliably produce correct answers
- Token budget at 60K starves investigation — ROI math says budget is irrelevant

Contracts completed: `consumer-ergonomics`, `walker-experience`, `ouroboros-seed-pipeline`, `kami-live-debugger`, `kabuki-presentation-engine`, `demo-presentation`.

Demo overhaul contract (`improve-asterisk-kabuki-demo`) deferred to Sprint R4 — no point polishing a demo for a system with arbitrary metrics.

Full PoC history: `notes/goal-history-poc.md`

## What "system-refined" means

### Asterisk
- [ ] Every metric threshold has a documented rationale (baseline, ceiling, ROI)
- [ ] ScoreCard YAML replaces hardcoded thresholds in metrics.go
- [ ] CursorAdapter M19 >= 0.70 with principled weights
- [ ] M14b (smoking gun) passes at >= 0.30
- [ ] Token budget at 200,000 (ROI-justified)
- [ ] RTFM deleted — ReadPolicy + prompt injection replaces `internal/rtfm/`
- [ ] 3 YAML pipelines (RCA, ingestion, calibration)
- [ ] CLI migrated to `origami.NewCLI()` scaffold
- [ ] EvidenceGap output when confidence is low
- [ ] TokiMeter deleted — cost bill from Origami `dispatch.FormatCostBill()`
- [ ] `StepNameFunc` adapter for display names (maps F0-F6 to human names)

### Origami
- [ ] `MetricDef`, `ScoreCard` types in `calibrate/` package
- [ ] ScoreCard YAML loader with direction-aware evaluation
- [ ] `MetricSet` is flat — `Metrics []Metric` with `ByTier()`/`ByID()` view methods
- [ ] `DefaultMetrics()` ships 7 universal metrics (token_usage, token_cost_usd, latency_seconds, path_efficiency, loop_ratio, confidence_calibration, run_variance)
- [ ] `DefaultScoreCard()` — three-layer API following Go slog pattern
- [ ] TokiMeter cost bill in `dispatch/cost_bill.go` — every dispatch gets a cost bill. `BuildCostBill(TokenSummary, ...CostBillOption)` with `WithStepNames`, `WithCaseMetadata`
- [ ] `FormatTokenSummary` uses `CostConfig` (bug fix — no more hardcoded 3.0/15.0)
- [ ] Calibration runner as DSL pipeline (visible in Kami)
- [ ] `origami.NewCLI()` builder with 8 perennial commands
- [ ] `Checkpointer` interface + HITL Interrupt/Resume
- [ ] FQCN resolution on all registries + `imports:` on PipelineDef
- [ ] Namespaced, searchable, persistent `MemoryStore`
- [ ] `Marble` interface + `marble:` DSL field + composite subgraph
- [ ] Node caching + fan-in merge strategies
- [ ] Dispatch fallback chains
- [ ] Every walk emits OTel trace (root span = walk, child spans = nodes)
- [ ] `/metrics` endpoint on KamiServer (Prometheus)
- [ ] `DefaultObservability()` requires zero config
- [ ] Achilles can define its own ScoreCard without touching Origami code
- [ ] LSP validates pipeline YAML with completion and hover docs
- [ ] `KnownModels` replaced by configurable `ModelRegistry` (YAML-loadable, `RegisterModel()` API)
- [ ] `curate.Source` renamed to `curate.EvidenceSource` — no naming collision with `knowledge.Source`
- [ ] Ouroboros probe stimuli loadable from config — not hardcoded Go/HTTP scenarios
- [ ] `Mean`/`Stddev`/`SafeDiv` extracted from `calibrate/` to `internal/mathutil/`

## Goal Transition Protocol

When system refinement is complete:

1. Archive this manifest in `notes/` as `goal-history-refinement.md`
2. Restore presentation goal — Sprint R4 demo with principled, working system
3. Reassess all draft contracts — re-tier relative to the next goal
